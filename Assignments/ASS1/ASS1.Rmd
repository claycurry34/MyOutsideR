---
title: "Assignment 1"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Completed 14/15 questions

## Question 1
A table depicting grade calculation for this class, including grading scale.
```{r}
GradCalc <- data.frame(c(15, 10, 10, 10, 5, 20, 30))
GradCalc <- data.frame(GradCalc, c("Assignments", "Laboratories", "Projects (1/3 Project 1; 2/3 Project 2)", "In class Quizzes", "Canvas chapter quizzes", "Mid-Term Exams (x2)", "Final"))
GradCalc <- data.frame(GradCalc, c("A", "B", "C", "D", "F", "", ""))
GradCalc <- data.frame(GradCalc, c("90s","80s", "60s and 70s", "50s", "<50", "",""))

knitr::kable(GradCalc, col.names = c("Weight %", "Component", "Letter", "Score"))
```

## Question 2


### 2A.


```{r}
DDT<-read.csv("../../MyData/DDT.csv") # Reads in DDT
m=with(DDT, as.numeric(factor(MILE))) # A, could also be m=as.numeric(DDT$MILE)
n<-length(unique(m)) #B
mileCol <- with(DDT, m, col = 1:n)
coplot(LENGTH~WEIGHT|RIVER*SPECIES, data = DDT, col = mileCol)

```


### 2B.
The lower left 3 plots show the length of catfish vs weight across the rivers FCM, LCM, SCM, TRM.

### 2C.
The factor() function extracts the discrete values from DDT$MILE. The as.numeric() function converts factor() into a numerical vector, and with() evaluates as.numeric(factor()) in a local environment constructed from DDT.

### 2D.
The unique() function returns a vector containing a single instance of each mile observation. The length() function gets the length of this vector.

### 2E.
Plots are empty where the frequency of observations equals zero. Notice how LMBASS and SMBUFFALO were not observed in any river outside of TRM.

```{r}
DDT[DDT$RIVER!="TRM" & (DDT$SPECIES=="SMBUFFALO" | DDT$SPECIES=="LMBASS"),]
```

### 2F.
The arithmetic mean for DDT found in the sample of CCATFISH caught in the FCM river:

```{r}
mean(with(DDT[DDT$RIVER=="FCM" & DDT$SPECIES=="CCATFISH",], DDT))
```




## Question 3

### a.
ratio

### b.
ratio

### c.
nominal

### d.
ratio

### e.
ordinal

### f.
ratio

### g.
nominal

## Question 4
Let $\Omega$ denote some data set containing (possibly infinite) experimental units characterizing some phenomenon of interest to us.

### Simple Random Sampling
The set $S \subset \Omega$ constitutes a **simple random sample** when every $\omega \in \Omega$ has an equal chance of being included in $S$.

An example would be selecting data points at random from a hat while blindfolded. There are other, more sophisticated techniques.

### Stratified Random Sampling
The set $S \subset \Omega$ constitutes a **stratified random sample** when the $\Omega$ can be partitioned into two or more groups $G_1, G_2, \dots$ called *strata* where each $\omega \in G_i, \hspace{3pt}i=j$ shares some characteristic(s) with other elements in $G_i, \hspace{3pt}i=j$, which it does not share with elements in $\omega \in G_i, \hspace{3pt}i \ne j$.

An example would be a pre-election poll in which a right-leaning candidate is only interested in the ranking of important of issues among right-leaning voters, namely which issues motivate right-leaning voters to show up to the polls. This candidate may also be interested in polling left-leaning voters to gather information on which issues are likely to cause left-leaning voters show up to the polls, avoiding discussions on these issues in public settings.

### Cluster Sampling
The set $S \subset \Omega$ constitutes a **cluster sample** when the $\Omega$ can be partitioned into two or more groups $G_1, G_2, \dots$ where each $\omega \in G_i, \hspace{3pt}i=j$ constitutes a group of physically related (sequentially, geographically, ...) units.

Here are some examples: cell phone coverage in various cities, self-reported confidence levels in STEM programs according to gender, likely targets for software bugs for a program analyzed according to related modules modules.

### Systematic Sampling
The set $S \subset \Omega$ constitutes a **systematic sample** when each $\omega \in S$ is selected according to a regular rule, such as choosing at time intervals, or selecting every *k*th unit from a production. 

## Question 5
### MS 1.15
Listing wells from 5 random samples. . .
```{r}
mtbe <- read.csv("../../MyData/MTBE.csv")
size <- dim(mtbe)
size=size[1]
samp <- mtbe[sample(1:size, 5, replace=FALSE),]

samp
```

### (a) Additional Problems

#### (i) Removing rows with one or more NA


```{r}
mtbeo=na.omit(mtbe)
depth <- mtbeo[mtbeo$Aquifier=="Bedrock",]$Depth
mDepth = mean(depth)
```


#### (ii) Calculating standard Deviation
```{r}
BDepSD = sqrt(sum((depth-mDepth)^2)/(length(depth)-1))
BDepSD
```

## Question 6
### MS 1.16

```{r}
EARTHQUAKE <- readxl::read_xls("../../MyData/0-XLS/EARTHQUAKE.XLS")
ind <- sample(1:2929, 30, replace=FALSE)
eq <- EARTHQUAKE[ind,]
```

### additional problems

#### (i) plotting . . .

```{r}
plot(ts(eq$MAGNITUDE))
```

#### (ii) median . . .

```{r}
median(eq$MAGNITUDE)
```


## Question 7. 

### (a)

Fish specimen were collected at each of the river and tributary creek locations. These locations represent the different trata for the study.

### (b)

The target population is of all fish in the Tennessee River and its tributaries.

### (c)

The qualitative variables are RIVER and SPECIES.

## Question 8

```{r}
freq=c(15,8,63,20)
RL=c("None", "Both", "Legs0", "Wheels0")
l=rep(RL,freq)
source('C:/Dev/R_Projects/MATH4753CURR0011/R/pareto.R')
pareto(l, mn = "Pareto barplot")
```

## Question 9
Constructing some pie charts . . .

```{r}

pie(c(32,6,12), labels = c("Windows", "Explorer", "Office"), col=1:3, radius=1, main="Vulnerabilities by Target")

pie(c(6,8,22,3,11), labels = c("Denial of Service", "Information Disclosure", "Remote code execution", "Spoofing", "Privilege elevation"), col=1:5, radius = 1, main = "Vulnerabilities by Type")
```

## Question 10

```{r}
swd=read.csv("../../MyData/SWDEFECTS.csv", header=TRUE)
library(plotrix)
tab=table(swd$defect)
rtab=tab/sum(tab)
pie3D(rtab,labels=list("OK","Defective"),main="pie plot of SWD")
```

## Question 11

### A & B.
```{r}
VOLTAGE=read.csv("../../MyData/VOLTAGE.csv")
inc=(10.6-8.0)/9
cl=seq(8.0,10.6,by=inc)

old<-VOLTAGE[VOLTAGE$LOCATION=="OLD",]$VOLTAGE
oldC=cut(old,breaks=cl,ord=TRUE)
foldC <- as.data.frame(table(oldC))$Freq
foldC <- foldC/length(old)

barplot(foldC, space=0, main="Frequency Histogram (OLD)", names.arg = c("8.0-8.29","8.29-8.58","8.58-8.87","8.87-9.16", "9.16-9.44", "9.44-9.73", "9.73-10.0", "10.0-10.3", "10.3-10.6"),ylab ="relative frequency", xlab="voltage bin", ylim=c(0,0.8), cex.names = 0.7)

stem(as.numeric(oldC))
```

### c.
```{r}
new<-VOLTAGE[VOLTAGE$LOCATION=="NEW",]
new$VOLTAGE->vtn
vtn
max(vtn)
min(vtn)
lept<-min(vtn)-0.05
rept<-max(vtn)+0.05
rnge<-rept-lept
inc<-rnge/9
inc
seq(lept, rept,by=inc)->cl
cl
cvtn<-cut(vtn,breaks=cl)
new.tab=table(cvtn)
barplot(new.tab,space=0,main="Frequency Histogram(NEW)",las=2)
hist(vtn,nclass=10)


barplot(foldC, space=0, main="Frequency Histogram (OLD)", names.arg = c("8.0-8.29","8.29-8.58","8.58-8.87","8.87-9.16", "9.16-9.44", "9.44-9.73", "9.73-10.0", "10.0-10.3", "10.3-10.6"),ylab ="relative frequency", xlab="voltage bin", ylim=c(0,0.8), cex.names = 0.7)

```

### d.
In comparison to the old histogram, the new, locally-established manufacturing contains much greater variation about the mean. This means that a smaller portion of the voltage readings can be considered "good".

### e.
The preferred measure of central tendency is the arithmetic mean. This measure allows us to calculate the standard deviation from the mean.

```{r}

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

new<-VOLTAGE[VOLTAGE$LOCATION=="NEW",]$VOLTAGE
mean(new)
median(new)
getmode(new)


old<-VOLTAGE[VOLTAGE$LOCATION=="OLD",]$VOLTAGE
mean(old)
median(old)
getmode(old)



```

### f.
```{r}
z = (10.5-mean(old))/sd(old)
z
```

### g.
```{r}
z = (10.5-mean(new))/sd(new)
z
```

### h.
10.50 is much more likely to occur at the old location.

### i.
4 outliers were detected constructing a boxplot . . .

```{r}
boxplot(old, notch = TRUE)
```

### j.

```{r}
oldZ <- (old-mean(old))/sd(old)

old_possibleOutliers=old[abs(oldZ)>=2 & abs(oldZ)<=3]
old_possibleOutliers

old_definedOutliers=old[abs(oldZ)>3]
old_definedOutliers

```

### k.


```{r}
boxplot(new, notch = TRUE)
```

### l.

```{r}
newZ <- (new-mean(new))/sd(new)

new_possibleOutliers=new[abs(newZ)>=2 & abs(newZ)<=3]
new_possibleOutliers

new_definedOutliers=new[abs(newZ)>3]
new_definedOutliers

```

### m.

```{r}
library(ggplot2)

ggplot(VOLTAGE, aes(x=LOCATION,y=VOLTAGE)) + geom_boxplot() + ggtitle("Old and New Locations")
```

## Question 12
```{r}
ROUGHPIPE<-readxl::read_xls("../../MyData/0-XLS/ROUGHPIPE.XLS")
boxplot(ROUGHPIPE$ROUGH)
mean(ROUGHPIPE$ROUGH)
sd(ROUGHPIPE$ROUGH)

```

As the boxplot shows, the data is largely spread about the mean and median. Therefore, the best distribution estimator is Chebyshev's rule which says $(1- \frac{1}{5^2}) = .96 = 96\%$ percent of the distribution lies within 5 standard deviations of the mean. Therefore an interval guaranteed to contain 95% of the distribution would be (0, ```r mean(ROUGHPIPE$ROUGH)+5*sd(ROUGHPIPE$ROUGH)```).



## Question 13

## Question 14
### a.
```{r}
GALAXY2<-readxl::read_xls("../../MyData/0-XLS/GALAXY2.xls")
hist(GALAXY2$VELOCITY, breaks = seq(18000,25000,by=350))
```

### b.
The data shows a bi-modal distribution with little to no skewness in either distribution. Since many observations converge towards two different clusters, the evidence is strong that astronomers are measuring the velocities of two different bodies.

### c.
```{r}
G1 = GALAXY2[GALAXY2$VELOCITY<21500,]$VELOCITY
G2 = GALAXY2[GALAXY2$VELOCITY>=21500,]$VELOCITY
```
The mean velocity and standard deviation of the first cluster, A1775A, is $```r mean(G1)```$ and ```r sd(G1)```.
The mean velocity and standard deviation of the second cluster, A1775B, is $```r mean(G2)```$ and ```r sd(G2)```.

### d.
Galaxy A. Based on the numerical descriptive measures. An observation of 20000 has a Z-score in cluster A1775A of $z_A = $ ```r round((20000-mean(G1))/sd(G1), 2)``` and has a z-score in cluster A1775B $z_B = $ ```r round((20000-mean(G2))/sd(G2), 2)```.

Since $z_B$ is an outlier by definition, the observation certainly does not belong to A1775B.
Since $z_A$ tells us that 20000 is hardly 1 standard deviation from the mean, this observation is highly likely to belong to A1775A.


## Question 15
```{r}

library(ggplot2)
ddt <- read.csv("../../MyData/DDT.csv")

fishcol=with(ddt,ifelse(SPECIES=="CCATFISH","Red",
                        ifelse(SPECIES=="SMBUFFALO","Blue","Green")))
ggplot(ddt, aes(x=RIVER,y=LENGTH,fill=SPECIES)) + geom_boxplot()
```




