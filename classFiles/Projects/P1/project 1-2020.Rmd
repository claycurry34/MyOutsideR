---
title: "Project 1"
author: "Clay Curry"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    csl: biomed-central.csl
    df_print: paged
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
  pdf_document:
    df_print: kable
    <!-- fig_caption: yes
    fig_height: 6
    fig_width: 7 -->
    highlight: tango
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction to the data

## Data and Variables (see MS pg. 77,125)
Rigorous code evaluation in software development is critical for launching programs that with as little bugs and vulnerabilities as possible. As computer systems evolve, however, software engineers face the daunting task of having to retest their code for an infinitely growing number of additional vulnerabilities that new technology brings. In many ways, the cost of supporting rigorous code evaluations can grow to be much larger than the rewards of the software itself. When software engineers are hired to assess code, it is therefore necessary to devise systematic methods of triaging code and perform statistical analysis on their efficacy.

Certain guidelines were implemented by researchers to test various methods of triaging code. In the form of algorithms, these triaging methods were applied to 498 modules of code. The SWDEFECTS file contains a variable that corresponds to each method. When the method predicts a defect, the corresponding variable's value is "yes", and "no" otherwise. The accuracy of each method was determined by a complete evaluation of the code. The methods were evalued by computing several probability measures, called accuracy, detection rate, false alarm rate, and precision. 

## Summary Table 

TABLE SIA3.2 found on page 125.

```{r, echo=FALSE}
algoTabC1 = c("Algorithm", 
              "Predicts Defects", "")
algoTabC2 = c("No", 
            "Yes", 
             "")
algoTabC3 = c("False", 
                    "a",
                    "c")
algoTabC4 = c("True", 
                    "b",
                    "d")

algoSummaryTable = matrix(data = c(algoTabC1,algoTabC2,algoTabC3,algoTabC4), nrow=3, ncol = 4)
knitr::kable(algoSummaryTable, caption = "Summary Table for Evaluating Defect Prediction Algorithms", col.names = c("","","Has Defects",""))
```


$$
\text{Accuracy: } \ \ \ P(\text{Algorithm is correct}) =\frac{(a + d)}{(a + b + c + d)}
$$

$$
\text{Detection Rate: } \ \ \ P(\text{predict defect | module has defect}) =\frac{d}{(b + d)}
$$

$$
\text{False alarm Rate: } \ \ \ P(\text{predict defect | module has no defect}) =\frac{c}{(a + c)}
$$

$$
\text{Precision: } \ \ \ P(\text{module has defect | predict defect}) =\frac{d}{(c + d)}
$$

# R functions
Using the above definitions make R functions that will create the required probabilities, please remove `eval=FALSE` when creating the functions :

```{r accuracy, eval=FALSE}
acc=function(a,b,c,d)
{
  (a+d)/(a+b+c+d)
}
```

```{r detecton, eval=FALSE}
detect=function(b,d)
{
  d/(b+d)
}
```

```{r alarm, eval=FALSE}
falarm=function(a,c)
{
  c/(a+c)
}
```

```{r precision, eval=FALSE}
prec=function(c,d)
{
  d/(c+d)
}
```


# Create the tables in Figure SIA3.1

The tables do not have to be formatted exactly as those in the book. Have the functions produce a suitable barplot also. 

As a guide and help -- see code below


```{r cache=TRUE, include=FALSE}
SWDEFECTS <- read.csv("SWDEFECTS.csv")
colnames(SWDEFECTS)[colnames(SWDEFECTS)=="predict.loc.50"]="PREDICT_LOC"
colnames(SWDEFECTS)[colnames(SWDEFECTS)=="predict.vg.10"]="PREDICT_VG"
colnames(SWDEFECTS)[colnames(SWDEFECTS)=="predict.evg.14.5"]="PREDICT_EVG"
colnames(SWDEFECTS)[colnames(SWDEFECTS)=="predict.ivg.9.2"]="PREDICT_IVG"
```

```{r cache=TRUE}
tab1 = with(SWDEFECTS, table(PREDICT_LOC, defect))
tab2 = with(SWDEFECTS, table(PREDICT_VG, defect))
tab3 = with(SWDEFECTS, table(PREDICT_EVG, defect))
tab4 = with(SWDEFECTS, table(PREDICT_IVG, defect))

addmargins(tab1)
addmargins(tab2)
addmargins(tab3)
addmargins(tab4)
```


**Probability Measures for Evaluating Defect Prediction Algorithms**



```{r }
head(SWDEFECTS)
tab=with(SWDEFECTS, table(PREDICT_LOC,defect))
barplot(tab, beside=TRUE, leg=TRUE)
tab2=addmargins(tab)
tab2
```




# Create the corrected table on page 127 (there are mistakes in it), TABLE SIA3.3

```{r}
genRow = function(tab)
{
  df = data.frame(tab)
  a = df[df[1]=="no" & df[2]=="FALSE",3]
  b = df[df[1]=="no" & df[2]=="TRUE",3]
  c = df[df[1]=="yes" & df[2]=="FALSE",3]
  d = df[df[1]=="yes" & df[2]=="TRUE",3]
  AC = (a+d)/(a+b+c+d)
  DR = d/(b+d)
  FAR = c/(a+c)
  PR = d/(c+d)
  
  c(AC,DR, FAR, PR)
}
mybar = function(tab, acc = 3)
{
  barplot(tab, col = 1:4, beside = TRUE, legend.text = c("Lines of Code", "Cyclomatic Complexity", "Essential Complexity", "Design Complexity"), main = "Probability Measures for Evaluating Defect Predition Algorithms")
  
  tab = round(tab, acc)
  df = data.frame(tab, row.names = c("Lines of Code", "Cyclomatic Complexity", "Essential Complexity", "Design Complexity"))
  colnames(df) = c("Accuracy", "Detection Rate", "False Alarm Rate", "Precision")
  list(df)
}

mat = matrix(c(genRow(tab1), genRow(tab2), genRow(tab3), genRow(tab4)), nrow = 4, ncol = 4, byrow = TRUE)

mat

mybar(mat)
```

    
